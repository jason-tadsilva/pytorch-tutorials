{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n**Introduction to ONNX** ||\n[Exporting a PyTorch model to ONNX](export_simple_model_to_onnx_tutorial.html) ||\n[Extending the ONNX Registry](onnx_registry_tutorial.html)\n\n# Introduction to ONNX\n\nAuthors:\n[Thiago Crepaldi](https://github.com/thiagocrepaldi),\n\n[Open Neural Network eXchange (ONNX)](https://onnx.ai/) is an open standard\nformat for representing machine learning models. The ``torch.onnx`` module provides APIs to\ncapture the computation graph from a native PyTorch :class:`torch.nn.Module` model and convert\nit into an [ONNX graph](https://github.com/onnx/onnx/blob/main/docs/IR.md).\n\nThe exported model can be consumed by any of the many\n[runtimes that support ONNX](https://onnx.ai/supported-tools.html#deployModel),\nincluding Microsoft's [ONNX Runtime](https://www.onnxruntime.ai).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Currently, there are two flavors of ONNX exporter APIs,\n    but this tutorial will focus on the ``torch.onnx.dynamo_export``.</p></div>\n\nThe TorchDynamo engine is leveraged to hook into Python's frame evaluation API and dynamically rewrite its\nbytecode into an [FX graph](https://pytorch.org/docs/stable/fx.html).\nThe resulting FX Graph is polished before it is finally translated into an\n[ONNX graph](https://github.com/onnx/onnx/blob/main/docs/IR.md).\n\nThe main advantage of this approach is that the [FX graph](https://pytorch.org/docs/stable/fx.html) is captured using\nbytecode analysis that preserves the dynamic nature of the model instead of using traditional static tracing techniques.\n\n## Dependencies\n\nPyTorch 2.1.0 or newer is required.\n\nThe ONNX exporter depends on extra Python packages:\n\n  - [ONNX](https://onnx.ai) standard library\n  - [ONNX Script](https://onnxscript.ai) library that enables developers to author ONNX operators,\n    functions and models using a subset of Python in an expressive, and yet simple fashion.\n\nThey can be installed through [pip](https://pypi.org/project/pip/):\n\n```bash\npip install --upgrade onnx onnxscript\n```\nTo validate the installation, run the following commands:\n\n```python\nimport torch\nprint(torch.__version__)\n\nimport onnxscript\nprint(onnxscript.__version__)\n\nfrom onnxscript import opset18  # opset 18 is the latest (and only) supported version for now\n\nimport onnxruntime\nprint(onnxruntime.__version__)\n```\nEach `import` must succeed without any errors and the library versions must be printed out.\n\n## Further reading\n\nThe list below refers to tutorials that ranges from basic examples to advanced scenarios,\nnot necessarily in the order they are listed.\nFeel free to jump directly to specific topics of your interest or\nsit tight and have fun going through all of them to learn all there is about the ONNX exporter.\n\n.. include:: /beginner_source/onnx/onnx_toc.txt\n\n.. toctree::\n   :hidden:\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}